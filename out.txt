[[36m2025-06-09 14:55:54,665[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2025-06-09 14:55:54,669[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
â”œâ”€â”€ data
â”‚   â””â”€â”€ _target_: src.data.enhancer_train_datamodule.EnhancerTrainDataModule                                                  
â”‚       data_dir: /storage/gabriel/basen_train//                                                                              
â”‚       data_list: synth_lat_nfiq80_list_small.txt                                                                            
â”‚       lat_subdir: /synth_lat_nfiq80/                                                                                        
â”‚       ref_subdir: /ref_NFIQ80/                                                                                              
â”‚       skel_subdir: /ref_skel/                                                                                               
â”‚       bin_subdir: /ref_bin/                                                                                                 
â”‚       mask_subdir: /synth_lat_nfiq80_masks/0/                                                                               
â”‚       mnt_subdir: /mnts_ref_fusion/                                                                                         
â”‚       apply_mask: 1                                                                                                         
â”‚       batch_size: 128                                                                                                       
â”‚       train_val_split:                                                                                                      
â”‚       - 0.7                                                                                                                 
â”‚       - 0.3                                                                                                                 
â”‚       num_workers: 8                                                                                                        
â”‚       pin_memory: true                                                                                                      
â”‚                                                                                                                             
â”œâ”€â”€ model
â”‚   â””â”€â”€ _target_: src.models.enhancer_module.EnhancerLitModule                                                                
â”‚       optimizer:                                                                                                            
â”‚         _target_: torch.optim.AdamW                                                                                         
â”‚         _partial_: true                                                                                                     
â”‚         lr: 0.0001                                                                                                          
â”‚         weight_decay: 0.0004                                                                                                
â”‚       scheduler:                                                                                                            
â”‚         _target_: torch.optim.lr_scheduler.ReduceLROnPlateau                                                                
â”‚         _partial_: true                                                                                                     
â”‚         mode: min                                                                                                           
â”‚         factor: 0.1                                                                                                         
â”‚         patience: 2                                                                                                         
â”‚       net:                                                                                                                  
â”‚         _target_: src.models.components.ResUNet.ResUNet                                                                     
â”‚         in_ch: 1                                                                                                            
â”‚         ndim: 2                                                                                                             
â”‚         out_ch: 2                                                                                                           
â”‚       compile: false                                                                                                        
â”‚       output_path: /home/gabriel/fingerprint-enhancement/output/                                                            
â”‚       use_patches: false                                                                                                    
â”‚                                                                                                                             
â”œâ”€â”€ callbacks
â”‚   â””â”€â”€ model_checkpoint:                                                                                                     
â”‚         _target_: lightning.pytorch.callbacks.ModelCheckpoint                                                               
â”‚         dirpath: /home/gabriel/fingerprint-enhancement/logs/train/runs/2025-06-09_14-55-54/checkpoints                      
â”‚         filename: epoch_{epoch:03d}                                                                                         
â”‚         monitor: val/loss_best                                                                                              
â”‚         verbose: false                                                                                                      
â”‚         save_last: true                                                                                                     
â”‚         save_top_k: 1                                                                                                       
â”‚         mode: min                                                                                                           
â”‚         auto_insert_metric_name: false                                                                                      
â”‚         save_weights_only: false                                                                                            
â”‚         every_n_train_steps: null                                                                                           
â”‚         train_time_interval: null                                                                                           
â”‚         every_n_epochs: null                                                                                                
â”‚         save_on_train_epoch_end: null                                                                                       
â”‚       early_stopping:                                                                                                       
â”‚         _target_: lightning.pytorch.callbacks.EarlyStopping                                                                 
â”‚         monitor: val/loss_best                                                                                              
â”‚         min_delta: 0.0                                                                                                      
â”‚         patience: 100                                                                                                       
â”‚         verbose: false                                                                                                      
â”‚         mode: min                                                                                                           
â”‚         strict: true                                                                                                        
â”‚         check_finite: true                                                                                                  
â”‚         stopping_threshold: null                                                                                            
â”‚         divergence_threshold: null                                                                                          
â”‚         check_on_train_epoch_end: null                                                                                      
â”‚       model_summary:                                                                                                        
â”‚         _target_: lightning.pytorch.callbacks.RichModelSummary                                                              
â”‚         max_depth: -1                                                                                                       
â”‚       rich_progress_bar:                                                                                                    
â”‚         _target_: lightning.pytorch.callbacks.RichProgressBar                                                               
â”‚                                                                                                                             
â”œâ”€â”€ logger
â”‚   â””â”€â”€ mlflow:                                                                                                               
â”‚         _target_: lightning.pytorch.loggers.mlflow.MLFlowLogger                                                             
â”‚         experiment_name: fingerprint enhancer                                                                               
â”‚         tracking_uri: /home/gabriel/fingerprint-enhancement/logs//mlflow/mlruns                                             
â”‚         tags: null                                                                                                          
â”‚         prefix: ''                                                                                                          
â”‚         artifact_location: null                                                                                             
â”‚                                                                                                                             
â”œâ”€â”€ trainer
â”‚   â””â”€â”€ _target_: lightning.pytorch.trainer.Trainer                                                                           
â”‚       default_root_dir: /home/gabriel/fingerprint-enhancement/logs/train/runs/2025-06-09_14-55-54                           
â”‚       min_epochs: 1                                                                                                         
â”‚       max_epochs: 300                                                                                                       
â”‚       accelerator: gpu                                                                                                      
â”‚       devices: 4                                                                                                            
â”‚       precision: 16                                                                                                         
â”‚       check_val_every_n_epoch: 1                                                                                            
â”‚       deterministic: false                                                                                                  
â”‚                                                                                                                             
â”œâ”€â”€ paths
â”‚   â””â”€â”€ root_dir: /home/gabriel/fingerprint-enhancement                                                                       
â”‚       data_dir: /storage/gabriel/basen_train/                                                                               
â”‚       log_dir: /home/gabriel/fingerprint-enhancement/logs/                                                                  
â”‚       output_dir: /home/gabriel/fingerprint-enhancement/logs/train/runs/2025-06-09_14-55-54                                 
â”‚       work_dir: /home/gabriel/fingerprint-enhancement                                                                       
â”‚                                                                                                                             
â”œâ”€â”€ extras
â”‚   â””â”€â”€ ignore_warnings: false                                                                                                
â”‚       enforce_tags: true                                                                                                    
â”‚       print_config: true                                                                                                    
â”‚                                                                                                                             
â”œâ”€â”€ task_name
â”‚   â””â”€â”€ train                                                                                                                 
â”œâ”€â”€ tags
â”‚   â””â”€â”€ ['dev']                                                                                                               
â”œâ”€â”€ train
â”‚   â””â”€â”€ True                                                                                                                  
â”œâ”€â”€ test
â”‚   â””â”€â”€ False                                                                                                                 
â””â”€â”€ seed
    â””â”€â”€ None                                                                                                                  
[[36m2025-06-09 14:55:54,811[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating datamodule <src.data.enhancer_train_datamodule.EnhancerTrainDataModule>[0m
[[36m2025-06-09 14:55:54,817[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating model <src.models.enhancer_module.EnhancerLitModule>[0m
[[36m2025-06-09 14:55:54,903[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating callbacks...[0m
[[36m2025-06-09 14:55:54,904[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-06-09 14:55:54,908[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2025-06-09 14:55:54,909[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-06-09 14:55:54,910[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-06-09 14:55:54,910[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating loggers...[0m
[[36m2025-06-09 14:55:54,911[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <lightning.pytorch.loggers.mlflow.MLFlowLogger>[0m
[[36m2025-06-09 14:55:56,249[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-06-09 14:55:56,263[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Logging hyperparameters![0m
[[36m2025-06-09 14:55:56,478[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting training![0m
â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ     â”ƒ Name                                 â”ƒ Type              â”ƒ Params â”ƒ Mode  â”ƒ
â”¡â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ 0   â”‚ net                                  â”‚ ResUNet           â”‚  7.6 M â”‚ train â”‚
â”‚ 1   â”‚ net.encoder                          â”‚ Encoder           â”‚  4.9 M â”‚ train â”‚
â”‚ 2   â”‚ net.encoder.enc_blocks               â”‚ ModuleList        â”‚  4.9 M â”‚ train â”‚
â”‚ 3   â”‚ net.encoder.enc_blocks.0             â”‚ ResnetBlock       â”‚  9.8 K â”‚ train â”‚
â”‚ 4   â”‚ net.encoder.enc_blocks.0.block1      â”‚ Block             â”‚    384 â”‚ train â”‚
â”‚ 5   â”‚ net.encoder.enc_blocks.0.block1.proj â”‚ Conv2d            â”‚    320 â”‚ train â”‚
â”‚ 6   â”‚ net.encoder.enc_blocks.0.block1.norm â”‚ GroupNorm         â”‚     64 â”‚ train â”‚
â”‚ 7   â”‚ net.encoder.enc_blocks.0.block1.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 8   â”‚ net.encoder.enc_blocks.0.block2      â”‚ Block             â”‚  9.3 K â”‚ train â”‚
â”‚ 9   â”‚ net.encoder.enc_blocks.0.block2.proj â”‚ Conv2d            â”‚  9.2 K â”‚ train â”‚
â”‚ 10  â”‚ net.encoder.enc_blocks.0.block2.norm â”‚ GroupNorm         â”‚     64 â”‚ train â”‚
â”‚ 11  â”‚ net.encoder.enc_blocks.0.block2.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 12  â”‚ net.encoder.enc_blocks.0.res_conv    â”‚ Conv2d            â”‚     64 â”‚ train â”‚
â”‚ 13  â”‚ net.encoder.enc_blocks.1             â”‚ ResnetBlock       â”‚ 57.8 K â”‚ train â”‚
â”‚ 14  â”‚ net.encoder.enc_blocks.1.block1      â”‚ Block             â”‚ 18.6 K â”‚ train â”‚
â”‚ 15  â”‚ net.encoder.enc_blocks.1.block1.proj â”‚ Conv2d            â”‚ 18.5 K â”‚ train â”‚
â”‚ 16  â”‚ net.encoder.enc_blocks.1.block1.norm â”‚ GroupNorm         â”‚    128 â”‚ train â”‚
â”‚ 17  â”‚ net.encoder.enc_blocks.1.block1.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 18  â”‚ net.encoder.enc_blocks.1.block2      â”‚ Block             â”‚ 37.1 K â”‚ train â”‚
â”‚ 19  â”‚ net.encoder.enc_blocks.1.block2.proj â”‚ Conv2d            â”‚ 36.9 K â”‚ train â”‚
â”‚ 20  â”‚ net.encoder.enc_blocks.1.block2.norm â”‚ GroupNorm         â”‚    128 â”‚ train â”‚
â”‚ 21  â”‚ net.encoder.enc_blocks.1.block2.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 22  â”‚ net.encoder.enc_blocks.1.res_conv    â”‚ Conv2d            â”‚  2.1 K â”‚ train â”‚
â”‚ 23  â”‚ net.encoder.enc_blocks.2             â”‚ ResnetBlock       â”‚  230 K â”‚ train â”‚
â”‚ 24  â”‚ net.encoder.enc_blocks.2.block1      â”‚ Block             â”‚ 74.1 K â”‚ train â”‚
â”‚ 25  â”‚ net.encoder.enc_blocks.2.block1.proj â”‚ Conv2d            â”‚ 73.9 K â”‚ train â”‚
â”‚ 26  â”‚ net.encoder.enc_blocks.2.block1.norm â”‚ GroupNorm         â”‚    256 â”‚ train â”‚
â”‚ 27  â”‚ net.encoder.enc_blocks.2.block1.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 28  â”‚ net.encoder.enc_blocks.2.block2      â”‚ Block             â”‚  147 K â”‚ train â”‚
â”‚ 29  â”‚ net.encoder.enc_blocks.2.block2.proj â”‚ Conv2d            â”‚  147 K â”‚ train â”‚
â”‚ 30  â”‚ net.encoder.enc_blocks.2.block2.norm â”‚ GroupNorm         â”‚    256 â”‚ train â”‚
â”‚ 31  â”‚ net.encoder.enc_blocks.2.block2.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 32  â”‚ net.encoder.enc_blocks.2.res_conv    â”‚ Conv2d            â”‚  8.3 K â”‚ train â”‚
â”‚ 33  â”‚ net.encoder.enc_blocks.3             â”‚ ResnetBlock       â”‚  919 K â”‚ train â”‚
â”‚ 34  â”‚ net.encoder.enc_blocks.3.block1      â”‚ Block             â”‚  295 K â”‚ train â”‚
â”‚ 35  â”‚ net.encoder.enc_blocks.3.block1.proj â”‚ Conv2d            â”‚  295 K â”‚ train â”‚
â”‚ 36  â”‚ net.encoder.enc_blocks.3.block1.norm â”‚ GroupNorm         â”‚    512 â”‚ train â”‚
â”‚ 37  â”‚ net.encoder.enc_blocks.3.block1.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 38  â”‚ net.encoder.enc_blocks.3.block2      â”‚ Block             â”‚  590 K â”‚ train â”‚
â”‚ 39  â”‚ net.encoder.enc_blocks.3.block2.proj â”‚ Conv2d            â”‚  590 K â”‚ train â”‚
â”‚ 40  â”‚ net.encoder.enc_blocks.3.block2.norm â”‚ GroupNorm         â”‚    512 â”‚ train â”‚
â”‚ 41  â”‚ net.encoder.enc_blocks.3.block2.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 42  â”‚ net.encoder.enc_blocks.3.res_conv    â”‚ Conv2d            â”‚ 33.0 K â”‚ train â”‚
â”‚ 43  â”‚ net.encoder.enc_blocks.4             â”‚ ResnetBlock       â”‚  3.7 M â”‚ train â”‚
â”‚ 44  â”‚ net.encoder.enc_blocks.4.block1      â”‚ Block             â”‚  1.2 M â”‚ train â”‚
â”‚ 45  â”‚ net.encoder.enc_blocks.4.block1.proj â”‚ Conv2d            â”‚  1.2 M â”‚ train â”‚
â”‚ 46  â”‚ net.encoder.enc_blocks.4.block1.norm â”‚ GroupNorm         â”‚  1.0 K â”‚ train â”‚
â”‚ 47  â”‚ net.encoder.enc_blocks.4.block1.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 48  â”‚ net.encoder.enc_blocks.4.block2      â”‚ Block             â”‚  2.4 M â”‚ train â”‚
â”‚ 49  â”‚ net.encoder.enc_blocks.4.block2.proj â”‚ Conv2d            â”‚  2.4 M â”‚ train â”‚
â”‚ 50  â”‚ net.encoder.enc_blocks.4.block2.norm â”‚ GroupNorm         â”‚  1.0 K â”‚ train â”‚
â”‚ 51  â”‚ net.encoder.enc_blocks.4.block2.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 52  â”‚ net.encoder.enc_blocks.4.res_conv    â”‚ Conv2d            â”‚  131 K â”‚ train â”‚
â”‚ 53  â”‚ net.encoder.pool                     â”‚ MaxPool2d         â”‚      0 â”‚ train â”‚
â”‚ 54  â”‚ net.decoder                          â”‚ Decoder           â”‚  2.7 M â”‚ train â”‚
â”‚ 55  â”‚ net.decoder.upconvs                  â”‚ ModuleList        â”‚  174 K â”‚ train â”‚
â”‚ 56  â”‚ net.decoder.upconvs.0                â”‚ Sequential        â”‚  131 K â”‚ train â”‚
â”‚ 57  â”‚ net.decoder.upconvs.0.0              â”‚ Upsample          â”‚      0 â”‚ train â”‚
â”‚ 58  â”‚ net.decoder.upconvs.0.1              â”‚ Conv2d            â”‚  131 K â”‚ train â”‚
â”‚ 59  â”‚ net.decoder.upconvs.1                â”‚ Sequential        â”‚ 32.9 K â”‚ train â”‚
â”‚ 60  â”‚ net.decoder.upconvs.1.0              â”‚ Upsample          â”‚      0 â”‚ train â”‚
â”‚ 61  â”‚ net.decoder.upconvs.1.1              â”‚ Conv2d            â”‚ 32.9 K â”‚ train â”‚
â”‚ 62  â”‚ net.decoder.upconvs.2                â”‚ Sequential        â”‚  8.3 K â”‚ train â”‚
â”‚ 63  â”‚ net.decoder.upconvs.2.0              â”‚ Upsample          â”‚      0 â”‚ train â”‚
â”‚ 64  â”‚ net.decoder.upconvs.2.1              â”‚ Conv2d            â”‚  8.3 K â”‚ train â”‚
â”‚ 65  â”‚ net.decoder.upconvs.3                â”‚ Sequential        â”‚  2.1 K â”‚ train â”‚
â”‚ 66  â”‚ net.decoder.upconvs.3.0              â”‚ Upsample          â”‚      0 â”‚ train â”‚
â”‚ 67  â”‚ net.decoder.upconvs.3.1              â”‚ Conv2d            â”‚  2.1 K â”‚ train â”‚
â”‚ 68  â”‚ net.decoder.dec_blocks               â”‚ ModuleList        â”‚  2.5 M â”‚ train â”‚
â”‚ 69  â”‚ net.decoder.dec_blocks.0             â”‚ ResnetBlock       â”‚  1.9 M â”‚ train â”‚
â”‚ 70  â”‚ net.decoder.dec_blocks.0.block1      â”‚ Block             â”‚  1.2 M â”‚ train â”‚
â”‚ 71  â”‚ net.decoder.dec_blocks.0.block1.proj â”‚ Conv2d            â”‚  1.2 M â”‚ train â”‚
â”‚ 72  â”‚ net.decoder.dec_blocks.0.block1.norm â”‚ GroupNorm         â”‚    512 â”‚ train â”‚
â”‚ 73  â”‚ net.decoder.dec_blocks.0.block1.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 74  â”‚ net.decoder.dec_blocks.0.block2      â”‚ Block             â”‚  590 K â”‚ train â”‚
â”‚ 75  â”‚ net.decoder.dec_blocks.0.block2.proj â”‚ Conv2d            â”‚  590 K â”‚ train â”‚
â”‚ 76  â”‚ net.decoder.dec_blocks.0.block2.norm â”‚ GroupNorm         â”‚    512 â”‚ train â”‚
â”‚ 77  â”‚ net.decoder.dec_blocks.0.block2.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 78  â”‚ net.decoder.dec_blocks.0.res_conv    â”‚ Conv2d            â”‚  131 K â”‚ train â”‚
â”‚ 79  â”‚ net.decoder.dec_blocks.1             â”‚ ResnetBlock       â”‚  476 K â”‚ train â”‚
â”‚ 80  â”‚ net.decoder.dec_blocks.1.block1      â”‚ Block             â”‚  295 K â”‚ train â”‚
â”‚ 81  â”‚ net.decoder.dec_blocks.1.block1.proj â”‚ Conv2d            â”‚  295 K â”‚ train â”‚
â”‚ 82  â”‚ net.decoder.dec_blocks.1.block1.norm â”‚ GroupNorm         â”‚    256 â”‚ train â”‚
â”‚ 83  â”‚ net.decoder.dec_blocks.1.block1.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 84  â”‚ net.decoder.dec_blocks.1.block2      â”‚ Block             â”‚  147 K â”‚ train â”‚
â”‚ 85  â”‚ net.decoder.dec_blocks.1.block2.proj â”‚ Conv2d            â”‚  147 K â”‚ train â”‚
â”‚ 86  â”‚ net.decoder.dec_blocks.1.block2.norm â”‚ GroupNorm         â”‚    256 â”‚ train â”‚
â”‚ 87  â”‚ net.decoder.dec_blocks.1.block2.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 88  â”‚ net.decoder.dec_blocks.1.res_conv    â”‚ Conv2d            â”‚ 32.9 K â”‚ train â”‚
â”‚ 89  â”‚ net.decoder.dec_blocks.2             â”‚ ResnetBlock       â”‚  119 K â”‚ train â”‚
â”‚ 90  â”‚ net.decoder.dec_blocks.2.block1      â”‚ Block             â”‚ 73.9 K â”‚ train â”‚
â”‚ 91  â”‚ net.decoder.dec_blocks.2.block1.proj â”‚ Conv2d            â”‚ 73.8 K â”‚ train â”‚
â”‚ 92  â”‚ net.decoder.dec_blocks.2.block1.norm â”‚ GroupNorm         â”‚    128 â”‚ train â”‚
â”‚ 93  â”‚ net.decoder.dec_blocks.2.block1.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 94  â”‚ net.decoder.dec_blocks.2.block2      â”‚ Block             â”‚ 37.1 K â”‚ train â”‚
â”‚ 95  â”‚ net.decoder.dec_blocks.2.block2.proj â”‚ Conv2d            â”‚ 36.9 K â”‚ train â”‚
â”‚ 96  â”‚ net.decoder.dec_blocks.2.block2.norm â”‚ GroupNorm         â”‚    128 â”‚ train â”‚
â”‚ 97  â”‚ net.decoder.dec_blocks.2.block2.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 98  â”‚ net.decoder.dec_blocks.2.res_conv    â”‚ Conv2d            â”‚  8.3 K â”‚ train â”‚
â”‚ 99  â”‚ net.decoder.dec_blocks.3             â”‚ ResnetBlock       â”‚ 29.9 K â”‚ train â”‚
â”‚ 100 â”‚ net.decoder.dec_blocks.3.block1      â”‚ Block             â”‚ 18.5 K â”‚ train â”‚
â”‚ 101 â”‚ net.decoder.dec_blocks.3.block1.proj â”‚ Conv2d            â”‚ 18.5 K â”‚ train â”‚
â”‚ 102 â”‚ net.decoder.dec_blocks.3.block1.norm â”‚ GroupNorm         â”‚     64 â”‚ train â”‚
â”‚ 103 â”‚ net.decoder.dec_blocks.3.block1.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 104 â”‚ net.decoder.dec_blocks.3.block2      â”‚ Block             â”‚  9.3 K â”‚ train â”‚
â”‚ 105 â”‚ net.decoder.dec_blocks.3.block2.proj â”‚ Conv2d            â”‚  9.2 K â”‚ train â”‚
â”‚ 106 â”‚ net.decoder.dec_blocks.3.block2.norm â”‚ GroupNorm         â”‚     64 â”‚ train â”‚
â”‚ 107 â”‚ net.decoder.dec_blocks.3.block2.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 108 â”‚ net.decoder.dec_blocks.3.res_conv    â”‚ Conv2d            â”‚  2.1 K â”‚ train â”‚
â”‚ 109 â”‚ net.head                             â”‚ Conv2d            â”‚     66 â”‚ train â”‚
â”‚ 110 â”‚ criterion                            â”‚ BCEWithLogitsLoss â”‚      0 â”‚ train â”‚
â”‚ 111 â”‚ train_loss                           â”‚ MeanMetric        â”‚      0 â”‚ train â”‚
â”‚ 112 â”‚ val_loss                             â”‚ MeanMetric        â”‚      0 â”‚ train â”‚
â”‚ 113 â”‚ test_loss                            â”‚ MeanMetric        â”‚      0 â”‚ train â”‚
â”‚ 114 â”‚ val_loss_best                        â”‚ MinMetric         â”‚      0 â”‚ train â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 7.6 M                                                                                                       
Non-trainable params: 0                                                                                                       
Total params: 7.6 M                                                                                                           
Total estimated model params size (MB): 30                                                                                    
Modules in train mode: 115                                                                                                    
Modules in eval mode: 0                                                                                                       
torch.Size([])
torch.Size([])
torch.Size([])

[[36m2025-06-09 14:56:09,259[0m][[34msrc.utils.utils[0m][[31mERROR[0m] - [rank: 0] [0m
Traceback (most recent call last):
  File "/home/gabriel/fingerprint-enhancement/src/utils/utils.py", line 68, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/home/gabriel/fingerprint-enhancement/src/train.py", line 87, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1054, in _run_stage
    self._run_sanity_check()
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1083, in _run_sanity_check
    val_loop.run()
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 328, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 411, in validation_step
    return self._forward_redirection(self.model, self.lightning_module, "validation_step", *args, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 641, in __call__
    wrapper_output = wrapper_module(*args, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 634, in wrapped_forward
    out = method(*_args, **_kwargs)
  File "/home/gabriel/fingerprint-enhancement/src/models/enhancer_module.py", line 254, in validation_step
    loss = self.model_step(batch)
  File "/home/gabriel/fingerprint-enhancement/src/models/enhancer_module.py", line 222, in model_step
    return loss
NameError: name 'loss' is not defined
[[36m2025-06-09 14:56:09,271[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Output dir: /home/gabriel/fingerprint-enhancement/logs/train/runs/2025-06-09_14-55-54[0m
torch.Size([])
[[36m2025-06-09 14:56:51,410[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2025-06-09 14:56:51,414[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
â”œâ”€â”€ data
â”‚   â””â”€â”€ _target_: src.data.enhancer_train_datamodule.EnhancerTrainDataModule                                                  
â”‚       data_dir: /storage/gabriel/basen_train//                                                                              
â”‚       data_list: synth_lat_nfiq80_list_small.txt                                                                            
â”‚       lat_subdir: /synth_lat_nfiq80/                                                                                        
â”‚       ref_subdir: /ref_NFIQ80/                                                                                              
â”‚       skel_subdir: /ref_skel/                                                                                               
â”‚       bin_subdir: /ref_bin/                                                                                                 
â”‚       mask_subdir: /synth_lat_nfiq80_masks/0/                                                                               
â”‚       mnt_subdir: /mnts_ref_fusion/                                                                                         
â”‚       apply_mask: 1                                                                                                         
â”‚       batch_size: 128                                                                                                       
â”‚       train_val_split:                                                                                                      
â”‚       - 0.7                                                                                                                 
â”‚       - 0.3                                                                                                                 
â”‚       num_workers: 8                                                                                                        
â”‚       pin_memory: true                                                                                                      
â”‚                                                                                                                             
â”œâ”€â”€ model
â”‚   â””â”€â”€ _target_: src.models.enhancer_module.EnhancerLitModule                                                                
â”‚       optimizer:                                                                                                            
â”‚         _target_: torch.optim.AdamW                                                                                         
â”‚         _partial_: true                                                                                                     
â”‚         lr: 0.0001                                                                                                          
â”‚         weight_decay: 0.0004                                                                                                
â”‚       scheduler:                                                                                                            
â”‚         _target_: torch.optim.lr_scheduler.ReduceLROnPlateau                                                                
â”‚         _partial_: true                                                                                                     
â”‚         mode: min                                                                                                           
â”‚         factor: 0.1                                                                                                         
â”‚         patience: 2                                                                                                         
â”‚       net:                                                                                                                  
â”‚         _target_: src.models.components.ResUNet.ResUNet                                                                     
â”‚         in_ch: 1                                                                                                            
â”‚         ndim: 2                                                                                                             
â”‚         out_ch: 2                                                                                                           
â”‚       compile: false                                                                                                        
â”‚       output_path: /home/gabriel/fingerprint-enhancement/output/                                                            
â”‚       use_patches: false                                                                                                    
â”‚                                                                                                                             
â”œâ”€â”€ callbacks
â”‚   â””â”€â”€ model_checkpoint:                                                                                                     
â”‚         _target_: lightning.pytorch.callbacks.ModelCheckpoint                                                               
â”‚         dirpath: /home/gabriel/fingerprint-enhancement/logs/train/runs/2025-06-09_14-56-51/checkpoints                      
â”‚         filename: epoch_{epoch:03d}                                                                                         
â”‚         monitor: val/loss_best                                                                                              
â”‚         verbose: false                                                                                                      
â”‚         save_last: true                                                                                                     
â”‚         save_top_k: 1                                                                                                       
â”‚         mode: min                                                                                                           
â”‚         auto_insert_metric_name: false                                                                                      
â”‚         save_weights_only: false                                                                                            
â”‚         every_n_train_steps: null                                                                                           
â”‚         train_time_interval: null                                                                                           
â”‚         every_n_epochs: null                                                                                                
â”‚         save_on_train_epoch_end: null                                                                                       
â”‚       early_stopping:                                                                                                       
â”‚         _target_: lightning.pytorch.callbacks.EarlyStopping                                                                 
â”‚         monitor: val/loss_best                                                                                              
â”‚         min_delta: 0.0                                                                                                      
â”‚         patience: 100                                                                                                       
â”‚         verbose: false                                                                                                      
â”‚         mode: min                                                                                                           
â”‚         strict: true                                                                                                        
â”‚         check_finite: true                                                                                                  
â”‚         stopping_threshold: null                                                                                            
â”‚         divergence_threshold: null                                                                                          
â”‚         check_on_train_epoch_end: null                                                                                      
â”‚       model_summary:                                                                                                        
â”‚         _target_: lightning.pytorch.callbacks.RichModelSummary                                                              
â”‚         max_depth: -1                                                                                                       
â”‚       rich_progress_bar:                                                                                                    
â”‚         _target_: lightning.pytorch.callbacks.RichProgressBar                                                               
â”‚                                                                                                                             
â”œâ”€â”€ logger
â”‚   â””â”€â”€ mlflow:                                                                                                               
â”‚         _target_: lightning.pytorch.loggers.mlflow.MLFlowLogger                                                             
â”‚         experiment_name: fingerprint enhancer                                                                               
â”‚         tracking_uri: /home/gabriel/fingerprint-enhancement/logs//mlflow/mlruns                                             
â”‚         tags: null                                                                                                          
â”‚         prefix: ''                                                                                                          
â”‚         artifact_location: null                                                                                             
â”‚                                                                                                                             
â”œâ”€â”€ trainer
â”‚   â””â”€â”€ _target_: lightning.pytorch.trainer.Trainer                                                                           
â”‚       default_root_dir: /home/gabriel/fingerprint-enhancement/logs/train/runs/2025-06-09_14-56-51                           
â”‚       min_epochs: 1                                                                                                         
â”‚       max_epochs: 300                                                                                                       
â”‚       accelerator: gpu                                                                                                      
â”‚       devices: 4                                                                                                            
â”‚       precision: 16                                                                                                         
â”‚       check_val_every_n_epoch: 1                                                                                            
â”‚       deterministic: false                                                                                                  
â”‚                                                                                                                             
â”œâ”€â”€ paths
â”‚   â””â”€â”€ root_dir: /home/gabriel/fingerprint-enhancement                                                                       
â”‚       data_dir: /storage/gabriel/basen_train/                                                                               
â”‚       log_dir: /home/gabriel/fingerprint-enhancement/logs/                                                                  
â”‚       output_dir: /home/gabriel/fingerprint-enhancement/logs/train/runs/2025-06-09_14-56-51                                 
â”‚       work_dir: /home/gabriel/fingerprint-enhancement                                                                       
â”‚                                                                                                                             
â”œâ”€â”€ extras
â”‚   â””â”€â”€ ignore_warnings: false                                                                                                
â”‚       enforce_tags: true                                                                                                    
â”‚       print_config: true                                                                                                    
â”‚                                                                                                                             
â”œâ”€â”€ task_name
â”‚   â””â”€â”€ train                                                                                                                 
â”œâ”€â”€ tags
â”‚   â””â”€â”€ ['dev']                                                                                                               
â”œâ”€â”€ train
â”‚   â””â”€â”€ True                                                                                                                  
â”œâ”€â”€ test
â”‚   â””â”€â”€ False                                                                                                                 
â””â”€â”€ seed
    â””â”€â”€ None                                                                                                                  
[[36m2025-06-09 14:56:51,555[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating datamodule <src.data.enhancer_train_datamodule.EnhancerTrainDataModule>[0m
[[36m2025-06-09 14:56:51,562[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating model <src.models.enhancer_module.EnhancerLitModule>[0m
[[36m2025-06-09 14:56:51,647[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating callbacks...[0m
[[36m2025-06-09 14:56:51,647[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-06-09 14:56:51,652[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2025-06-09 14:56:51,653[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-06-09 14:56:51,654[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-06-09 14:56:51,654[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating loggers...[0m
[[36m2025-06-09 14:56:51,654[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <lightning.pytorch.loggers.mlflow.MLFlowLogger>[0m
[[36m2025-06-09 14:56:52,995[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-06-09 14:56:53,009[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Logging hyperparameters![0m
[[36m2025-06-09 14:56:53,224[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting training![0m
â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ     â”ƒ Name                                 â”ƒ Type              â”ƒ Params â”ƒ Mode  â”ƒ
â”¡â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ 0   â”‚ net                                  â”‚ ResUNet           â”‚  7.6 M â”‚ train â”‚
â”‚ 1   â”‚ net.encoder                          â”‚ Encoder           â”‚  4.9 M â”‚ train â”‚
â”‚ 2   â”‚ net.encoder.enc_blocks               â”‚ ModuleList        â”‚  4.9 M â”‚ train â”‚
â”‚ 3   â”‚ net.encoder.enc_blocks.0             â”‚ ResnetBlock       â”‚  9.8 K â”‚ train â”‚
â”‚ 4   â”‚ net.encoder.enc_blocks.0.block1      â”‚ Block             â”‚    384 â”‚ train â”‚
â”‚ 5   â”‚ net.encoder.enc_blocks.0.block1.proj â”‚ Conv2d            â”‚    320 â”‚ train â”‚
â”‚ 6   â”‚ net.encoder.enc_blocks.0.block1.norm â”‚ GroupNorm         â”‚     64 â”‚ train â”‚
â”‚ 7   â”‚ net.encoder.enc_blocks.0.block1.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 8   â”‚ net.encoder.enc_blocks.0.block2      â”‚ Block             â”‚  9.3 K â”‚ train â”‚
â”‚ 9   â”‚ net.encoder.enc_blocks.0.block2.proj â”‚ Conv2d            â”‚  9.2 K â”‚ train â”‚
â”‚ 10  â”‚ net.encoder.enc_blocks.0.block2.norm â”‚ GroupNorm         â”‚     64 â”‚ train â”‚
â”‚ 11  â”‚ net.encoder.enc_blocks.0.block2.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 12  â”‚ net.encoder.enc_blocks.0.res_conv    â”‚ Conv2d            â”‚     64 â”‚ train â”‚
â”‚ 13  â”‚ net.encoder.enc_blocks.1             â”‚ ResnetBlock       â”‚ 57.8 K â”‚ train â”‚
â”‚ 14  â”‚ net.encoder.enc_blocks.1.block1      â”‚ Block             â”‚ 18.6 K â”‚ train â”‚
â”‚ 15  â”‚ net.encoder.enc_blocks.1.block1.proj â”‚ Conv2d            â”‚ 18.5 K â”‚ train â”‚
â”‚ 16  â”‚ net.encoder.enc_blocks.1.block1.norm â”‚ GroupNorm         â”‚    128 â”‚ train â”‚
â”‚ 17  â”‚ net.encoder.enc_blocks.1.block1.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 18  â”‚ net.encoder.enc_blocks.1.block2      â”‚ Block             â”‚ 37.1 K â”‚ train â”‚
â”‚ 19  â”‚ net.encoder.enc_blocks.1.block2.proj â”‚ Conv2d            â”‚ 36.9 K â”‚ train â”‚
â”‚ 20  â”‚ net.encoder.enc_blocks.1.block2.norm â”‚ GroupNorm         â”‚    128 â”‚ train â”‚
â”‚ 21  â”‚ net.encoder.enc_blocks.1.block2.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 22  â”‚ net.encoder.enc_blocks.1.res_conv    â”‚ Conv2d            â”‚  2.1 K â”‚ train â”‚
â”‚ 23  â”‚ net.encoder.enc_blocks.2             â”‚ ResnetBlock       â”‚  230 K â”‚ train â”‚
â”‚ 24  â”‚ net.encoder.enc_blocks.2.block1      â”‚ Block             â”‚ 74.1 K â”‚ train â”‚
â”‚ 25  â”‚ net.encoder.enc_blocks.2.block1.proj â”‚ Conv2d            â”‚ 73.9 K â”‚ train â”‚
â”‚ 26  â”‚ net.encoder.enc_blocks.2.block1.norm â”‚ GroupNorm         â”‚    256 â”‚ train â”‚
â”‚ 27  â”‚ net.encoder.enc_blocks.2.block1.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 28  â”‚ net.encoder.enc_blocks.2.block2      â”‚ Block             â”‚  147 K â”‚ train â”‚
â”‚ 29  â”‚ net.encoder.enc_blocks.2.block2.proj â”‚ Conv2d            â”‚  147 K â”‚ train â”‚
â”‚ 30  â”‚ net.encoder.enc_blocks.2.block2.norm â”‚ GroupNorm         â”‚    256 â”‚ train â”‚
â”‚ 31  â”‚ net.encoder.enc_blocks.2.block2.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 32  â”‚ net.encoder.enc_blocks.2.res_conv    â”‚ Conv2d            â”‚  8.3 K â”‚ train â”‚
â”‚ 33  â”‚ net.encoder.enc_blocks.3             â”‚ ResnetBlock       â”‚  919 K â”‚ train â”‚
â”‚ 34  â”‚ net.encoder.enc_blocks.3.block1      â”‚ Block             â”‚  295 K â”‚ train â”‚
â”‚ 35  â”‚ net.encoder.enc_blocks.3.block1.proj â”‚ Conv2d            â”‚  295 K â”‚ train â”‚
â”‚ 36  â”‚ net.encoder.enc_blocks.3.block1.norm â”‚ GroupNorm         â”‚    512 â”‚ train â”‚
â”‚ 37  â”‚ net.encoder.enc_blocks.3.block1.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 38  â”‚ net.encoder.enc_blocks.3.block2      â”‚ Block             â”‚  590 K â”‚ train â”‚
â”‚ 39  â”‚ net.encoder.enc_blocks.3.block2.proj â”‚ Conv2d            â”‚  590 K â”‚ train â”‚
â”‚ 40  â”‚ net.encoder.enc_blocks.3.block2.norm â”‚ GroupNorm         â”‚    512 â”‚ train â”‚
â”‚ 41  â”‚ net.encoder.enc_blocks.3.block2.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 42  â”‚ net.encoder.enc_blocks.3.res_conv    â”‚ Conv2d            â”‚ 33.0 K â”‚ train â”‚
â”‚ 43  â”‚ net.encoder.enc_blocks.4             â”‚ ResnetBlock       â”‚  3.7 M â”‚ train â”‚
â”‚ 44  â”‚ net.encoder.enc_blocks.4.block1      â”‚ Block             â”‚  1.2 M â”‚ train â”‚
â”‚ 45  â”‚ net.encoder.enc_blocks.4.block1.proj â”‚ Conv2d            â”‚  1.2 M â”‚ train â”‚
â”‚ 46  â”‚ net.encoder.enc_blocks.4.block1.norm â”‚ GroupNorm         â”‚  1.0 K â”‚ train â”‚
â”‚ 47  â”‚ net.encoder.enc_blocks.4.block1.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 48  â”‚ net.encoder.enc_blocks.4.block2      â”‚ Block             â”‚  2.4 M â”‚ train â”‚
â”‚ 49  â”‚ net.encoder.enc_blocks.4.block2.proj â”‚ Conv2d            â”‚  2.4 M â”‚ train â”‚
â”‚ 50  â”‚ net.encoder.enc_blocks.4.block2.norm â”‚ GroupNorm         â”‚  1.0 K â”‚ train â”‚
â”‚ 51  â”‚ net.encoder.enc_blocks.4.block2.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 52  â”‚ net.encoder.enc_blocks.4.res_conv    â”‚ Conv2d            â”‚  131 K â”‚ train â”‚
â”‚ 53  â”‚ net.encoder.pool                     â”‚ MaxPool2d         â”‚      0 â”‚ train â”‚
â”‚ 54  â”‚ net.decoder                          â”‚ Decoder           â”‚  2.7 M â”‚ train â”‚
â”‚ 55  â”‚ net.decoder.upconvs                  â”‚ ModuleList        â”‚  174 K â”‚ train â”‚
â”‚ 56  â”‚ net.decoder.upconvs.0                â”‚ Sequential        â”‚  131 K â”‚ train â”‚
â”‚ 57  â”‚ net.decoder.upconvs.0.0              â”‚ Upsample          â”‚      0 â”‚ train â”‚
â”‚ 58  â”‚ net.decoder.upconvs.0.1              â”‚ Conv2d            â”‚  131 K â”‚ train â”‚
â”‚ 59  â”‚ net.decoder.upconvs.1                â”‚ Sequential        â”‚ 32.9 K â”‚ train â”‚
â”‚ 60  â”‚ net.decoder.upconvs.1.0              â”‚ Upsample          â”‚      0 â”‚ train â”‚
â”‚ 61  â”‚ net.decoder.upconvs.1.1              â”‚ Conv2d            â”‚ 32.9 K â”‚ train â”‚
â”‚ 62  â”‚ net.decoder.upconvs.2                â”‚ Sequential        â”‚  8.3 K â”‚ train â”‚
â”‚ 63  â”‚ net.decoder.upconvs.2.0              â”‚ Upsample          â”‚      0 â”‚ train â”‚
â”‚ 64  â”‚ net.decoder.upconvs.2.1              â”‚ Conv2d            â”‚  8.3 K â”‚ train â”‚
â”‚ 65  â”‚ net.decoder.upconvs.3                â”‚ Sequential        â”‚  2.1 K â”‚ train â”‚
â”‚ 66  â”‚ net.decoder.upconvs.3.0              â”‚ Upsample          â”‚      0 â”‚ train â”‚
â”‚ 67  â”‚ net.decoder.upconvs.3.1              â”‚ Conv2d            â”‚  2.1 K â”‚ train â”‚
â”‚ 68  â”‚ net.decoder.dec_blocks               â”‚ ModuleList        â”‚  2.5 M â”‚ train â”‚
â”‚ 69  â”‚ net.decoder.dec_blocks.0             â”‚ ResnetBlock       â”‚  1.9 M â”‚ train â”‚
â”‚ 70  â”‚ net.decoder.dec_blocks.0.block1      â”‚ Block             â”‚  1.2 M â”‚ train â”‚
â”‚ 71  â”‚ net.decoder.dec_blocks.0.block1.proj â”‚ Conv2d            â”‚  1.2 M â”‚ train â”‚
â”‚ 72  â”‚ net.decoder.dec_blocks.0.block1.norm â”‚ GroupNorm         â”‚    512 â”‚ train â”‚
â”‚ 73  â”‚ net.decoder.dec_blocks.0.block1.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 74  â”‚ net.decoder.dec_blocks.0.block2      â”‚ Block             â”‚  590 K â”‚ train â”‚
â”‚ 75  â”‚ net.decoder.dec_blocks.0.block2.proj â”‚ Conv2d            â”‚  590 K â”‚ train â”‚
â”‚ 76  â”‚ net.decoder.dec_blocks.0.block2.norm â”‚ GroupNorm         â”‚    512 â”‚ train â”‚
â”‚ 77  â”‚ net.decoder.dec_blocks.0.block2.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 78  â”‚ net.decoder.dec_blocks.0.res_conv    â”‚ Conv2d            â”‚  131 K â”‚ train â”‚
â”‚ 79  â”‚ net.decoder.dec_blocks.1             â”‚ ResnetBlock       â”‚  476 K â”‚ train â”‚
â”‚ 80  â”‚ net.decoder.dec_blocks.1.block1      â”‚ Block             â”‚  295 K â”‚ train â”‚
â”‚ 81  â”‚ net.decoder.dec_blocks.1.block1.proj â”‚ Conv2d            â”‚  295 K â”‚ train â”‚
â”‚ 82  â”‚ net.decoder.dec_blocks.1.block1.norm â”‚ GroupNorm         â”‚    256 â”‚ train â”‚
â”‚ 83  â”‚ net.decoder.dec_blocks.1.block1.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 84  â”‚ net.decoder.dec_blocks.1.block2      â”‚ Block             â”‚  147 K â”‚ train â”‚
â”‚ 85  â”‚ net.decoder.dec_blocks.1.block2.proj â”‚ Conv2d            â”‚  147 K â”‚ train â”‚
â”‚ 86  â”‚ net.decoder.dec_blocks.1.block2.norm â”‚ GroupNorm         â”‚    256 â”‚ train â”‚
â”‚ 87  â”‚ net.decoder.dec_blocks.1.block2.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 88  â”‚ net.decoder.dec_blocks.1.res_conv    â”‚ Conv2d            â”‚ 32.9 K â”‚ train â”‚
â”‚ 89  â”‚ net.decoder.dec_blocks.2             â”‚ ResnetBlock       â”‚  119 K â”‚ train â”‚
â”‚ 90  â”‚ net.decoder.dec_blocks.2.block1      â”‚ Block             â”‚ 73.9 K â”‚ train â”‚
â”‚ 91  â”‚ net.decoder.dec_blocks.2.block1.proj â”‚ Conv2d            â”‚ 73.8 K â”‚ train â”‚
â”‚ 92  â”‚ net.decoder.dec_blocks.2.block1.norm â”‚ GroupNorm         â”‚    128 â”‚ train â”‚
â”‚ 93  â”‚ net.decoder.dec_blocks.2.block1.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 94  â”‚ net.decoder.dec_blocks.2.block2      â”‚ Block             â”‚ 37.1 K â”‚ train â”‚
â”‚ 95  â”‚ net.decoder.dec_blocks.2.block2.proj â”‚ Conv2d            â”‚ 36.9 K â”‚ train â”‚
â”‚ 96  â”‚ net.decoder.dec_blocks.2.block2.norm â”‚ GroupNorm         â”‚    128 â”‚ train â”‚
â”‚ 97  â”‚ net.decoder.dec_blocks.2.block2.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 98  â”‚ net.decoder.dec_blocks.2.res_conv    â”‚ Conv2d            â”‚  8.3 K â”‚ train â”‚
â”‚ 99  â”‚ net.decoder.dec_blocks.3             â”‚ ResnetBlock       â”‚ 29.9 K â”‚ train â”‚
â”‚ 100 â”‚ net.decoder.dec_blocks.3.block1      â”‚ Block             â”‚ 18.5 K â”‚ train â”‚
â”‚ 101 â”‚ net.decoder.dec_blocks.3.block1.proj â”‚ Conv2d            â”‚ 18.5 K â”‚ train â”‚
â”‚ 102 â”‚ net.decoder.dec_blocks.3.block1.norm â”‚ GroupNorm         â”‚     64 â”‚ train â”‚
â”‚ 103 â”‚ net.decoder.dec_blocks.3.block1.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 104 â”‚ net.decoder.dec_blocks.3.block2      â”‚ Block             â”‚  9.3 K â”‚ train â”‚
â”‚ 105 â”‚ net.decoder.dec_blocks.3.block2.proj â”‚ Conv2d            â”‚  9.2 K â”‚ train â”‚
â”‚ 106 â”‚ net.decoder.dec_blocks.3.block2.norm â”‚ GroupNorm         â”‚     64 â”‚ train â”‚
â”‚ 107 â”‚ net.decoder.dec_blocks.3.block2.act  â”‚ SiLU              â”‚      0 â”‚ train â”‚
â”‚ 108 â”‚ net.decoder.dec_blocks.3.res_conv    â”‚ Conv2d            â”‚  2.1 K â”‚ train â”‚
â”‚ 109 â”‚ net.head                             â”‚ Conv2d            â”‚     66 â”‚ train â”‚
â”‚ 110 â”‚ criterion                            â”‚ BCEWithLogitsLoss â”‚      0 â”‚ train â”‚
â”‚ 111 â”‚ train_loss                           â”‚ MeanMetric        â”‚      0 â”‚ train â”‚
â”‚ 112 â”‚ val_loss                             â”‚ MeanMetric        â”‚      0 â”‚ train â”‚
â”‚ 113 â”‚ test_loss                            â”‚ MeanMetric        â”‚      0 â”‚ train â”‚
â”‚ 114 â”‚ val_loss_best                        â”‚ MinMetric         â”‚      0 â”‚ train â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 7.6 M                                                                                                       
Non-trainable params: 0                                                                                                       
Total params: 7.6 M                                                                                                           
Total estimated model params size (MB): 30                                                                                    
Modules in train mode: 115                                                                                                    
Modules in eval mode: 0                                                                                                       
tensor(0.5465, device='cuda:0')

[[36m2025-06-09 14:57:06,218[0m][[34msrc.utils.utils[0m][[31mERROR[0m] - [rank: 0] [0m
Traceback (most recent call last):
  File "/home/gabriel/fingerprint-enhancement/src/utils/utils.py", line 68, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/home/gabriel/fingerprint-enhancement/src/train.py", line 87, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1054, in _run_stage
    self._run_sanity_check()
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1083, in _run_sanity_check
    val_loop.run()
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 328, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 411, in validation_step
    return self._forward_redirection(self.model, self.lightning_module, "validation_step", *args, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 641, in __call__
    wrapper_output = wrapper_module(*args, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gabriel/miniconda3/envs/hydra/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 634, in wrapped_forward
    out = method(*_args, **_kwargs)
  File "/home/gabriel/fingerprint-enhancement/src/models/enhancer_module.py", line 254, in validation_step
    loss = self.model_step(batch)
  File "/home/gabriel/fingerprint-enhancement/src/models/enhancer_module.py", line 222, in model_step
    return loss
NameError: name 'loss' is not defined
[[36m2025-06-09 14:57:06,233[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Output dir: /home/gabriel/fingerprint-enhancement/logs/train/runs/2025-06-09_14-56-51[0m
tensor(0.5018, device='cuda:3')
tensor(0.5113, device='cuda:2')
tensor(0.5225, device='cuda:1')
